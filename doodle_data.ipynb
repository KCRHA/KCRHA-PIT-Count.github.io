{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a09236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "370506ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the relative path for the exports\n",
    "rel_path = \"C://Users/ben_g/OneDrive - King County Regional Homelessness Authority/Research and Data - 2026 Unsheltered PIT/Volunteer Training & Schedule/Doodle Exports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76beec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# loop over the list of workbooks\n",
    "subregions = [\n",
    "    \"Vashon Island\",\n",
    "    \"South Seattle\",\n",
    "    \"South King County\",\n",
    "    \"South East King County\",\n",
    "    \"Snoqualmie Valley\",\n",
    "    \"North Seattle\",\n",
    "    \"North King County\",\n",
    "    \"Family Phone Line\",\n",
    "    \"East King County\",\n",
    "    \"Downtown Seattle\"\n",
    "]\n",
    "\n",
    "# create dataframe to concatentate workbooks into\n",
    "all_regions = pd.DataFrame()\n",
    "\n",
    "# loop over the list, creating an Excel workbook of results\n",
    "# --------------\n",
    "for region in subregions:\n",
    "    # get the source export\n",
    "    path = f\"{rel_path}/{region}.xlsx\" # MAY NEED TO SPECIFY\n",
    "    # read into a pandas dataframe\n",
    "    workbook = pd.read_excel(io=path,\n",
    "                            header=5,\n",
    "                            index_col=0,\n",
    "                            engine='openpyxl')\n",
    "    \n",
    "    # do a little cleaning\n",
    "    workbook = workbook.drop(columns=[\"email\",\n",
    "                                    \"Volunteer Emergency Contact Name (Last, First)\",\n",
    "                                    \"Volunteer Emergency Contact Phone Number\",\n",
    "                                    \"Volunteer Phone Number\",\n",
    "                                    \"Waiver Completed?\"])\n",
    "    \n",
    "    # transpose the dataframe\n",
    "    workbook = workbook.T\n",
    "\n",
    "    # reset the index\n",
    "    workbook = workbook.reset_index(names=\"DateTime\")\n",
    "\n",
    "    # split 'DateTime' into two columns\n",
    "    # ----------------------------------\n",
    "    # look for a space preceded by 4 digits\n",
    "    split_data = workbook['DateTime'].str.split(r'(?<=\\d{4})\\s', expand=True)\n",
    "\n",
    "    workbook['Date'] = split_data[0]\n",
    "    workbook['Time'] = split_data[1]\n",
    "\n",
    "    # groupby columns to handle duplicate columns\n",
    "    workbook = workbook.groupby(level=0,\n",
    "                                axis=1).first()\n",
    "    \n",
    "    # replace all \"Signed-up\" with \"Time\"\n",
    "    for col in workbook.columns:\n",
    "        # print(col)\n",
    "        workbook.loc[workbook[col] == \"Signed-up\", col] = workbook['Time']\n",
    "\n",
    "    # drop newly extraneous columns\n",
    "    workbook = workbook.drop(columns=[\"DateTime\",\n",
    "                                    \"Time\",\n",
    "                                    \"Total seats\",\n",
    "                                    \"Participants signed-up\"])\n",
    "\n",
    "    # reset the index to be the \"Date\" col (ahead of transposing)\n",
    "    workbook = workbook.set_index(keys=\"Date\")\n",
    "\n",
    "    # add the subregion name as a feature\n",
    "    workbook[\"Subregion\"] = region\n",
    "\n",
    "    # concatentate to the big dataframe\n",
    "    all_regions = pd.concat([all_regions, workbook])\n",
    "\n",
    "    # loop over the locations to create dataframes similar to the excel tracker\n",
    "    # ------------------\n",
    "    # get a list of unique locations\n",
    "    locations = list(set(workbook[\"Session description\"]))\n",
    "\n",
    "    # create a dictionary to hold the indexed dataframes\n",
    "    dfs = {}\n",
    "\n",
    "    # loop over each location to create a separate, named df\n",
    "    for loc in locations:\n",
    "        # create dataframes as transposed copies\n",
    "        # -------------------\n",
    "        # filter for target location\n",
    "        df = workbook[workbook[\"Session description\"]==loc].copy()\n",
    "\n",
    "        # drop the \"Session description\" from the newly created df\n",
    "        df = df.drop(columns=[\"Session description\"])\n",
    "\n",
    "        # convert the \"Date\" column to datetime\n",
    "        df.index = pd.to_datetime(df.index,\n",
    "                                    errors=\"coerce\")\n",
    "\n",
    "        # transpose the dataframe and drop empty rows\n",
    "        df = df.T.dropna(how='all')\n",
    "\n",
    "        # group by column and take the 'first' non-null entries\n",
    "        df = df.groupby(level=0,\n",
    "                        axis=1).first()\n",
    "        \n",
    "        # order the dataframe columns chronologically\n",
    "        df = df.sort_index(axis=1)\n",
    "\n",
    "        # reset the index so we don't lose names\n",
    "        df = df.reset_index()\n",
    " \n",
    "        # limit the sheet name len to avoid errors\n",
    "        if len(loc)>31:\n",
    "            loc = str(loc[:31])\n",
    "\n",
    "        # WRITE TO EXCEL WORKBOOK\n",
    "        # -------------------\n",
    "        # create the ExcelWriter object\n",
    "        with pd.ExcelWriter('C://Users/ben_g/OneDrive - King County Regional Homelessness Authority/Research and Data - 2026 Unsheltered PIT/Volunteer Training & Schedule/Volunteer Schedules - Doodle.xlsx',\n",
    "                            engine='openpyxl',\n",
    "                            mode='a',\n",
    "                            if_sheet_exists='replace') as writer:\n",
    "            # index=False prevents the 0, 1, 2... row numbers from being saved\n",
    "            df.to_excel(writer, sheet_name=loc, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab91886e",
   "metadata": {},
   "source": [
    "# Transform '_workbook_' for Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e61dc76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index so that we can manipulate 'Date'\n",
    "all_regions = all_regions.reset_index(names=\"Date\")\n",
    "\n",
    "# convert 'Date' column to datetime obj\n",
    "all_regions[\"Date\"] = pd.to_datetime(all_regions[\"Date\"], errors='coerce').dt.strftime('%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a407468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set 'Date' and 'Session description' as multiindex before grouping columns\n",
    "all_regions = all_regions.set_index(keys=[\"Date\", \"Session description\", \"Subregion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7715a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby columns to handle duplicate columns\n",
    "grouped_wbk = all_regions.stack().groupby(level=[0,1,2]).value_counts().reset_index(name=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53f5561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to handle the time transformation\n",
    "def parse_shift_times(df, column_name='level_3'):\n",
    "    # clean the string: remove the \".1\" duplicates and split by newline\n",
    "    # This separates \"10:00 AM\" from \"4 h\"\n",
    "    temp_split = df[column_name].str.replace(r'\\.\\d+$', '', regex=True).str.split('\\n', expand=True)\n",
    "    \n",
    "    # convert the first part to a datetime (Shift Start)\n",
    "    df['Shift Start'] = pd.to_datetime(temp_split[0], format='%I:%M %p').dt.time\n",
    "    \n",
    "    # convert the second part to a Timedelta (Duration)\n",
    "    # clean the duration string to make it compatible with pandas (e.g., \"4 h 30 min\" -> \"4h 30m\")\n",
    "    duration_str = temp_split[1].str.replace(' h', 'h').str.replace(' min', 'm')\n",
    "    duration_td = pd.to_timedelta(duration_str)\n",
    "    \n",
    "    # calculate Shift End\n",
    "    # combine a dummy date with the start time to do the math, then extract the time\n",
    "    dummy_date = pd.to_datetime('2026-01-01 ' + temp_split[0])\n",
    "    df['Shift End'] = (dummy_date + duration_td).dt.time\n",
    "\n",
    "    # drop the source column\n",
    "    df = df.drop(columns=[\"level_3\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# apply the function to your 'grouped_wbk' dataframe\n",
    "grouped_wbk = parse_shift_times(grouped_wbk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b1ffbb",
   "metadata": {},
   "source": [
    "# Create JSON Representation for Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39b78fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the color palette by site\n",
    "# (use limited palette, sites by subregion)\n",
    "site_colors = {\n",
    "    # Downtown Seattle\n",
    "    \"Mary's Place\":\"#172B69\",\n",
    "    \"St. James Cathedral\":\"#1B8477\",\n",
    "    \"Youthcare Orion\":\"#A5C04D\",\n",
    "    \"Compass Day Center\":\"#FFD600\",\n",
    "    # East King County\n",
    "    \"Bellevue Library\":\"#172B69\",\n",
    "    \"Issaquah Community Hall\":\"#1B8477\",\n",
    "    \"Overlake Christian Church\":\"#A5C04D\",\n",
    "    \"Kirkland Library\":\"#FFD600\",\n",
    "    # Family Phone Line\n",
    "    \"Mary's Place Phone Line\":\"#172B69\",\n",
    "    # North King County\n",
    "    \"Shoreline Library\":\"#172B69\",\n",
    "    \"Ronald United Methodist Church\":\"#1B8477\",\n",
    "    # North Seattle\n",
    "    \"North Seattle College\":\"#172B69\",\n",
    "    \"Lake City Library\":\"#1B8477\",\n",
    "    # Snoqualmie Valley\n",
    "    \"Reclaim\":\"#172B69\",\n",
    "    \"North Bend Library\":\"#1B8477\",\n",
    "    # South East King County\n",
    "    \"Maple Valley Food Bank\":\"#172B69\",\n",
    "    \"Plateau Outreach Ministries\":\"#1B8477\",\n",
    "    # South King County\n",
    "    \"Kent Library\":\"#172B69\",\n",
    "    \"Highline United Methodist Church\":\"#1B8477\",\n",
    "    \"Federal Way Library\":\"#A5C04D\",\n",
    "    \"Renton Library\":\"#FFD600\",\n",
    "    # South Seattle\n",
    "    \"Southwest Library\":\"#172B69\",\n",
    "    \"Georgetown SVP\":\"#1B8477\",\n",
    "    \"South Lucille VA Center\":\"#A5C04D\",\n",
    "    \"South Park Library\":\"#FFD600\",\n",
    "    # Vashon Island\n",
    "    \"Vashon Island Library\":\"#172B69\",\n",
    "    \"Vashon Food Bank\":\"#1B8477\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69cc2e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ISO 8601 strings for Start and End\n",
    "# assumes 'Date' is already a string or datetime object\n",
    "grouped_wbk['iso_start'] = pd.to_datetime(grouped_wbk['Date'] \\\n",
    "                                          .astype(str) + \\\n",
    "                                            ' ' + \\\n",
    "                                                grouped_wbk['Shift Start'] \\\n",
    "                                                    .astype(str)).dt \\\n",
    "                                                        .strftime('%Y-%m-%dT%H:%M:%S')\n",
    "grouped_wbk['iso_end'] = pd.to_datetime(grouped_wbk['Date'] \\\n",
    "                                        .astype(str) + \\\n",
    "                                            ' ' + \\\n",
    "                                                grouped_wbk['Shift End'] \\\n",
    "                                                    .astype(str)).dt \\\n",
    "                                                        .strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "# convert to a list of dictionaries\n",
    "# we can include 'Count' in the title so users see how many volunteers are there\n",
    "calendar_data = []\n",
    "for _, row in grouped_wbk.iterrows():\n",
    "    calendar_data.append({\n",
    "        \"title\": f\"{row['Session description']}\\n({row['Count']})\", # use \\n for the break\n",
    "        \"start\": row['iso_start'],\n",
    "        \"end\": row['iso_end'],\n",
    "        \"backgroundColor\": site_colors.get(row['Session description'], \"#6c757d\"),\n",
    "        \"borderColor\": \"transparent\",\n",
    "        \"allDay\": False,\n",
    "        \"extendedProps\": {\n",
    "            \"site\": row['Session description'],\n",
    "            \"subregion\": row['Subregion'],\n",
    "            \"volCount\": row['Count'] # store the raw number just in case\n",
    "        }\n",
    "    })\n",
    "\n",
    "# export to a JSON file for your website\n",
    "with open('schedule.json', 'w') as f:\n",
    "    json.dump(calendar_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
